{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Table of Contents\n",
    "* [build and  update](#build-and--update)\n",
    "\t* [load](#load)\n",
    "\t* [stage1](#stage1)\n",
    "\t* [stage3](#stage3)\n",
    "\t* [inspect](#inspect)\n",
    "* [parsing](#parsing)\n",
    "* [mkdocs/ s3 dev](#mkdocs/-s3-dev)\n",
    "* [clean and spellcheck](#clean-and-spellcheck)\n",
    "* [hide](#hide)\n",
    "\t* [old build and update ds](#old-build-and-update-ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import itertools\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# build and  update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from amt_utils import flintstones_pipeline\n",
    "from amt_utils.mturk import unpickle_this, pickle_this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "selection_metadata_dir = 'Flintstone_Shots_GIF_Selection'\n",
    "\n",
    "with open(os.path.join(selection_metadata_dir, 'beta_gif_names.json')) as f:\n",
    "    beta_videos = json.load(f)\n",
    "        \n",
    "with open(os.path.join(selection_metadata_dir, 'production_gif_names.json')) as f:\n",
    "    production_videos = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "processed_stage_1_a = unpickle_this('./stage_1/processed_stage1_boxes.pkl')\n",
    "\n",
    "processed_stage_1_b = unpickle_this('./stage_1/stage_1b_prod_all_boxes_8_29.pkl')\n",
    "\n",
    "stage_3a_settings = unpickle_this('stage_3/stage3_prod1_2_settings.pkl')\n",
    "\n",
    "stage_3b_descriptions =  unpickle_this('stage_3/stage3_prod1_2_descriptions.pkl')\n",
    "\n",
    "stage_3b_parses = unpickle_this('stage_3/stage3_prod1_2_descriptions_parses.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# vid_bins = unpickle_this('vid_bin_assignments.pkl')\n",
    "\n",
    "# vid_bin_lookup = {}\n",
    "# for k, vals in vid_bins.items():\n",
    "#     for v in vals:\n",
    "#         vid_bin_lookup[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "with open('ds_production.json') as f:\n",
    "    prod_batch_1 = json.load(f)[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-0a1cce4e11a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprod_batch_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'globalID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprod_batch_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-0a1cce4e11a8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprod_batch_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'globalID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprod_batch_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "prod_batch_1 = [vid['globalID'] for vid in prod_batch_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## stage1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# prod_dataset = flintstones_pipeline.FlintstonesDataset([vid_id])\n",
    "prod_dataset = flintstones_pipeline.FlintstonesDataset(prod_batch_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "prod_dataset.update_s1a(processed_stage_1_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# sorted_vids = prod_dataset.sorted_by_episode()\n",
    "# prod_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "prod_dataset = flintstones_pipeline.FlintstonesDataset(prod_batch_1)\n",
    "prod_dataset.update_s1a(processed_stage_1_a)\n",
    "prod_dataset.update_s1b(processed_stage_1_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## stage3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "prod_dataset.update_s3a(stage_3a_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "prod_dataset.update_s3b(stage_3b_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"go count\": \"8504\",\n",
       "    \"reasons for removal\": {\n",
       "        \"characters not present in all frames\": \"2340\",\n",
       "        \"missing stage1a annotation\": \"1\",\n",
       "        \"missing stage1b annotation\": \"896\",\n",
       "        \"missing stage3a annotation\": \"4025\",\n",
       "        \"missing stage3b annotation\": \"2389\",\n",
       "        \"no consensus characters in stage1a\": \"1845\",\n",
       "        \"total removed\": \"11496\"\n",
       "    },\n",
       "    \"stage statuses\": {\n",
       "        \"stage_0\": \"1846\",\n",
       "        \"stage_1a\": \"3236\",\n",
       "        \"stage_1b\": \"4025\",\n",
       "        \"stage_3a\": \"2389\",\n",
       "        \"stage_3b\": \"8504\"\n",
       "    },\n",
       "    \"video count\": \"20000\"\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "go_vids = prod_dataset.filter_videos({'go': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pickle_this(go_vids, 'v0p2_to_parse.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# dataset_to_json(go_vids, '0p2_to_parse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "prod_dataset = flintstones_pipeline.FlintstonesDataset(prod_batch_1)\n",
    "prod_dataset.update_s1a(processed_stage_1_a)\n",
    "prod_dataset.update_s1b(processed_stage_1_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "prod_dataset.update_s3a(stage_3a_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "vid_id = 's_02_e_29_shot_014705_014779'\n",
    "inspect_vid = prod_dataset.get_video(vid_id)\n",
    "inspect_vid = prod_dataset.filter_videos({'go': True})[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# inspect_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# inspect_vid.display_gif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dfs = inspect_vid.display_bounding_boxes()\n",
    "# dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "three_frames  = inspect_vid.display_keyframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# three_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "local_path = '/Users/schwenk/wrk/animation_gan/ai2-vision-animation-gan/documentation/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "img_base_path = 'https://s3-us-west-2.amazonaws.com/ai2-vision-animation-gan/documentation/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "three_frames.save(local_path + inspect_vid.gid() + '_keyframes.png')\n",
    "dfs.save(local_path + inspect_vid.gid() + '_bboxes.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "inspect_vid.characters_present()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "char_names_by_id = [char.name() for char in sorted(inspect_vid.data()['characters'], key=lambda x: x.char_id())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "char_names_by_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# parsing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from phrase_cues.parsing import parse_video\n",
    "import spacy\n",
    "from nltk.parse.stanford import StanfordParser\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tree import ParentedTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.parse.corenlp import CoreNLPServer\n",
    "from nltk.parse.corenlp import CoreNLPParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def dataset_to_json(dataset, version, out_dir='dataset'):\n",
    "    to_json = copy.deepcopy(dataset)\n",
    "    for vid in to_json:\n",
    "        vid.vid_data['characters'] = [char.data() for char in vid.vid_data['characters']]\n",
    "\n",
    "    ds_json = [vid.vid_data for vid in to_json]\n",
    "    out_file = os.path.join(out_dir, 'dataset_v{}.json'.format(version))\n",
    "    with open(out_file, 'w') as f:\n",
    "        json.dump(ds_json, f, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "test_vids = go_vids[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "core_nlp_base = '/Users/schwenk/wrk/animation_gan/phrase_cues/deps/stanford_core_nlp/stanford-corenlp-full-2017-06-09/'\n",
    "\n",
    "# parser = StanfordParser(path_to_jar=core_nlp_base + 'stanford-corenlp-3.8.0.jar',\n",
    "#                         path_to_models_jar=core_nlp_base +'stanford-corenlp-3.8.0-models.jar')\n",
    "\n",
    "const_parse_path = '/Users/schwenk/wrk/animation_gan/build_dataset/dataset'\n",
    "const_parse_dir = 'const_parses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "core_parser = CoreNLPParser(url='http://localhost:9000')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8504/8504 [06:22<00:00, 22.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# with CoreNLPServer(path_to_jar=core_nlp_base + 'stanford-corenlp-3.8.0.jar', path_to_models_jar=core_nlp_base +'stanford-corenlp-3.8.0-models.jar') as server:\n",
    "for vid in tqdm(go_vids):\n",
    "    try:\n",
    "        parse_video(vid, nlp, core_parser)\n",
    "    except:\n",
    "        print(vid.gid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "coref_res = unpickle_this('coref_results_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "vid = test_vids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for vid in go_vids:\n",
    "    vid.vid_data['parse']['coref'] = coref_res[vid.gid()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dataset_to_json(go_vids, '0p3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# mkdocs/ s3 dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s3_doc_base_uri = 'https://s3-us-west-2.amazonaws.com/ai2-vision-animation-gan/documentation/images/'\n",
    "\n",
    "video_mkd_template = \"\"\"## Video ID {}\n",
    "\n",
    "![animation]({})\n",
    "\n",
    "![animation_frames]({})\n",
    "\n",
    "![bounding_boxes]({})\n",
    "\n",
    "### Setting:\n",
    "{}\n",
    "\n",
    "### Characters:\n",
    "{}\n",
    "\n",
    "### Description:\n",
    "{}\n",
    "\"\"\"\n",
    "\n",
    "def paginate_image_list(img_list, page_size):\n",
    "    num_sort = sorted(img_list, key=lambda x: x.replace('.png', '').zfill(4))\n",
    "    for i in range(0, len(num_sort), page_size):\n",
    "        yield num_sort[i:i + page_size]\n",
    "        \n",
    "def write_mkd_doc(doc, fp):\n",
    "    with open(fp, 'w') as f:\n",
    "        f.write(doc)\n",
    "        \n",
    "def format_characters(id_name_pairs):\n",
    "    char_base = ''\n",
    "    for char_id, char_name in id_name_pairs:\n",
    "        char_base += char_id + ': ' + char_name + '\\n\\n'\n",
    "    return char_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "video = inspect_vid\n",
    "\n",
    "entry_args = [\n",
    "    video.gid(),\n",
    "    video.display_gif(True),\n",
    "    s3_doc_base_uri + inspect_vid.gid() + '_keyframes.png',\n",
    "    s3_doc_base_uri + inspect_vid.gid() + '_bboxes.png',\n",
    "    video.setting(),\n",
    "    format_characters(video.characters_present()),\n",
    "    video.description()\n",
    "]\n",
    "video_entry = video_mkd_template.format(*entry_args)\n",
    "\n",
    "write_mkd_doc(video_entry, './documentation/docs/datapoint.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# clean and spellcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import enchant\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "import difflib\n",
    "import diff_match_patch\n",
    "\n",
    "dmp = diff_match_patch.diff_match_patch()\n",
    "\n",
    "edict = enchant.Dict(\"en_US\")\n",
    "anglo_edict = enchant.Dict(\"en_UK\")\n",
    "cached_sw = stopwords.words(\"english\") + list(string.punctuation)\n",
    "\n",
    "#         edict.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "other_chars_names = ['gazoo', 'lodabricks', 'slaghoople', 'poobaah']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "other_words = ['bandana', 'tv', 'bandana', 'bowtie', 'sabretooth', 'creepella', 'polkadot', \n",
    "               'turban', 'monical', 'unibrow', 'accordion', 'boutineer', 'handkerchief', 'xray', \n",
    "               'onesie', 'midcentury', 'cafe', 'squatty', 'earings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "words_to_remove = ['whine', 'turbine', 'accordant', 'according', 'turbid', 'voile', 'acous', 'google', 'leper', 'deres', 'powerless', 'powerfulness', 'fervent', 'weaning', 'grail']\n",
    "_ = [edict.remove_from_session(word) for word in words_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "_ = [[edict.add(char_word.lower()) for char_word in char.split()] for char in main_characters + other_chars_names + other_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "manual_corrections = {  'lieing': 'lying',\n",
    "                        'infront': 'in font',\n",
    "                        'ladie': 'lady',\n",
    "                        'servent': 'servant',\n",
    "                        'wiht': 'with',\n",
    "                        'preformer': 'performer',\n",
    "                        'hinging': 'hanging',\n",
    "                        'bule': 'blue',\n",
    "                        'yount': 'young',\n",
    "                      'od': 'old',\n",
    "                      'dres': 'dress',\n",
    "                      'handshacking': 'hand shaking',\n",
    "                      'cru': 'crew',\n",
    "                      'hankerchief': 'handkerchief',\n",
    "                      'cowbow': 'cowboy',\n",
    "                      'helmit': 'helmet',\n",
    "                      'wearning': 'wearing',\n",
    "                      'broen': 'wearing'\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     21
    ],
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def check_mispelled(word):\n",
    "    return word and word.isalpha() and not (edict.check(word) or anglo_edict.check(word) or edict.check(word[0].upper() + word[1:]))\n",
    "\n",
    "def check_word_rules(word):\n",
    "    split_len = 2 < min([len(w) for w in word.split()])\n",
    "    not_proper = word[0].islower()\n",
    "    return not_proper and split_len\n",
    "\n",
    "def correct_spelling_error(misspelled_word):\n",
    "    if misspelled_word in manual_corrections:\n",
    "        return manual_corrections[misspelled_word]\n",
    "    suggested_spellings = edict.suggest(misspelled_word)\n",
    "    match_ratios = [fuzz.token_sort_ratio(misspelled_word, word) for word in suggested_spellings]\n",
    "    words_sorted_by_ratio = sorted(zip(suggested_spellings, match_ratios), key=lambda x: x[1], reverse=True)\n",
    "    words_sorted_by_ratio = [wordscore for wordscore in words_sorted_by_ratio if check_word_rules(wordscore[0])]\n",
    "    check_compounds = [word[0] for word in words_sorted_by_ratio if word[0].replace(' ', '') == misspelled_word]\n",
    "    if check_compounds:\n",
    "        return check_compounds[0]\n",
    "    if words_sorted_by_ratio[0][1] > 80:\n",
    "        return words_sorted_by_ratio[0][0]\n",
    "\n",
    "    for word, score in words_sorted_by_ratio:\n",
    "        if score >= 75 and word[0] == misspelled_word[0]:\n",
    "            return word\n",
    "        elif score >= 75:                    \n",
    "            return word\n",
    "    return None\n",
    "\n",
    "def apply_spelling_fix(orig_text):\n",
    "    orig_text_tokens = wordpunct_tokenize(orig_text)\n",
    "    processed_tokens = []\n",
    "    for token in orig_text_tokens:\n",
    "        norm_token = token.lower()\n",
    "        if len(norm_token) < 4:\n",
    "            processed_tokens.append(token)\n",
    "            continue\n",
    "        if check_mispelled(norm_token):\n",
    "            suggested_replacements = edict.suggest(token)\n",
    "            replacement_text = correct_spelling_error(norm_token, suggested_replacements)\n",
    "            if replacement_text:\n",
    "                if norm_token[0].isupper():\n",
    "                    replacement_text = upper(replacement_text[0]) + replaced_text[1:]\n",
    "                processed_tokens.append(replacement_text)\n",
    "            else:\n",
    "                processed_tokens.append(token)\n",
    "        else:\n",
    "            processed_tokens.append(token)\n",
    "    return ' '.join(processed_tokens)\n",
    "\n",
    "def diff_corrected_text(orig_text, corrected_text):\n",
    "    diff = dmp.diff_main(orig_text, corrected_text)\n",
    "    return HTML(dmp.diff_prettyHtml(diff))\n",
    "\n",
    "def specify_lesson_q_path(lesson):\n",
    "    pass\n",
    "\n",
    "def apply_spelling_and_grammar_to_ds(ck12_ds):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def remove_empty_fields(video):\n",
    "    video.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dataset_v0p1 = copy.deepcopy(all_reasonably_sized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_changed = []\n",
    "for video in dataset_v0p1:\n",
    "    for char in video['characters']:\n",
    "        char_name_words = wordpunct_tokenize(char['characterName'])\n",
    "        misspellings = [check_mispelled(word) for word in char_name_words]\n",
    "        if sum(misspellings):\n",
    "            for idx, is_mispelled in enumerate(misspellings):\n",
    "                if is_mispelled:\n",
    "                    suggested_replacement = correct_spelling_error(char_name_words[idx])\n",
    "                    if suggested_replacement:\n",
    "                        words_changed.append([char_name_words[idx], suggested_replacement])\n",
    "                        char_name_words[idx] = suggested_replacement\n",
    "#                     print(char_name_words, suggested_replacement)\n",
    "#             print(char['characterName'], ' '.join(char_name_words).replace(' , ', ', ').replace(' . ', '.'))\n",
    "            char['characterName'] = ' '.join(char_name_words).replace(' , ', ', ').replace(' . ', '.')\n",
    "#         print(list(zip(char_name_words, misspellings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "len(words_changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for video in dataset_v0p1:\n",
    "    setting = video['setting']\n",
    "    setting_words = setting.split()\n",
    "    misspellings = [check_mispelled(word) for word  in setting_words]\n",
    "    if sum(misspellings):\n",
    "        for idx, is_mispelled in enumerate(misspellings):\n",
    "            if is_mispelled:\n",
    "                suggested_replacement = correct_spelling_error(setting_words[idx])\n",
    "                if suggested_replacement:\n",
    "                    words_changed.append([setting_words[idx], suggested_replacement])\n",
    "                    setting_words[idx] = suggested_replacement\n",
    "        video['setting'] = ' '.join(setting_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "pickle_this(dataset_v0p1, 'dataset_v0p1.pkl')\n",
    "\n",
    "with open('dataset_v0p1.json', 'w') as f:\n",
    "    json.dump(dataset_v0p1, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(np.random.rand(10, 4), columns=['a', 'b', 'c', 'd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "len(dataset_v0p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "len(dataset_v0p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dataset_v0p1[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "for video in dataset_v0p1:\n",
    "    if not video['setting']:\n",
    "        print(video['globalID'])\n",
    "    if not video['characters']:\n",
    "        print(video['globalID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# hide "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# ds_production = make_ds_skeleton(production_videos)\n",
    "# ds_complete_stage1_v1 = [vid for vid in ds_production if vid['globalID'] in processed_stage_1_a and vid['globalID'] in processed_stage_1_b]\n",
    "\n",
    "# stg1a = set(processed_stage_1_a.keys())\n",
    "# stg1b = set(processed_stage_1_b.keys())\n",
    "\n",
    "# len(stg1a.difference(stg1b))\n",
    "\n",
    "# single_clip = [vid for vid in ds_production if vid['globalID'] == 's_01_e_02_shot_014615_014689'][0]\n",
    "\n",
    "# pass_vids = [vid for bin_n, vid in vid_bins.items() if bin_n in pass_bins]\n",
    "# pass_vid_ids = set([item for sublist in pass_vids for item in sublist])\n",
    "\n",
    "# ds_complete_stage1_v1 = [vid for vid in ds_complete_stage1_v1 if vid['globalID'] in pass_vid_ids]\n",
    "\n",
    "# len(ds_complete_stage1_v1)\n",
    "\n",
    "# ds_complete_stage1_v1_all_clean = [vid for vid in ds_complete_stage1_v1 if vid['globalID'] not in shot_change]\n",
    "\n",
    "# len(ds_complete_stage1_v1_all_clean) / 12819\n",
    "\n",
    "# # weird_vid = [vid for vid in ds_complete_stage1_v1 if vid['globalID'] == 's_06_e_24_shot_005808_005882']\n",
    "\n",
    "# single_char_clips = [clip for clip in ds_complete_stage1_v1_all_clean if len(clip['characters']) == 1]\n",
    "\n",
    "# multi_char_clips = [clip for clip in ds_complete_stage1_v1_all_clean if len(clip['characters']) > 1 and len(clip['characters']) < 4]\n",
    "\n",
    "# all_reasonably_sized = [clip for clip in ds_complete_stage1_v1_all_clean if len(clip['characters']) > 0 and len(clip['characters']) < 4]\n",
    "\n",
    "# len(all_reasonably_sized)\n",
    "\n",
    "# # multi_char_sample = random.sample(multi_char_clips, 100)\n",
    "\n",
    "# len(multi_char_sample)\n",
    "\n",
    "# # pickle_this(multi_char_clips, 'stage_1_multi_char_sample.pkl')\n",
    "\n",
    "# # pickle_this(all_reasonably_sized, 'stage_1_less_than_4chars.pkl')\n",
    "\n",
    "# # pickle_this(single_char_clips, 'stage_1_single_char_updated.pkl')\n",
    "\n",
    "# # single_clip = three_char_clips[1]\n",
    "# # single_clip "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## old build and update ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # rem_reason = 'no characters annotated in stage1a'\n",
    "\n",
    "# filt_vids = prod_dataset.filter_videos({'reason': rem_reason})\n",
    "# len(filt_vids)\n",
    "\n",
    "# rand_vid = random.choice(filt_vids)\n",
    "# rand_vid.display_gif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for vid in go_vids:\n",
    "#     vid.vid_data['parse'] = stage_3b_parses[vid.gid()] \n",
    "\n",
    "# for vid in go_vids:\n",
    "#     vid.vid_data['characters'] = [char.data() for char in vid.vid_data['characters']]\n",
    "\n",
    "# ds_json = [vid.vid_data for vid in go_vids]\n",
    "\n",
    "# len(ds_json)\n",
    "\n",
    "# tc = ds_json[0]['characters'][0]\n",
    "\n",
    "# with open('dataset_v0p2.json', 'w') as f:\n",
    "#     json.dump(ds_json, f, sort_keys=True, indent=4)\n",
    "\n",
    "# demo_vid = prod_dataset.get_video('s_05_e_09_shot_032756_032830')\n",
    "\n",
    "# demo_vid.display_keyframes()\n",
    "\n",
    "# demo_vid.display_gif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
